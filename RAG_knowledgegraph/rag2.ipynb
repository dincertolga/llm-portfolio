{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from llama_index import (SimpleDirectoryReader,\n",
    "                         LLMPredictor,\n",
    "                         ServiceContext,\n",
    "                         KnowledgeGraphIndex)\n",
    "#\n",
    "from llama_index.graph_stores import SimpleGraphStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.llms import HuggingFaceInferenceAPI\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from llama_index.embeddings import LangchainEmbedding\n",
    "from pyvis.network import Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 15/15 [00:00<00:00, 515.68it/s]\n",
      "Processing nodes: 100%|██████████| 16/16 [02:28<00:00,  9.27s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "documents = SimpleDirectoryReader(\"/Users/tolgadincer/Documents/AI_Projects/RAG_KnowledgeGraph_Llama-Index/documents\").load_data()\n",
    "print(len(documents))\n",
    "index=KnowledgeGraphIndex.from_documents(documents,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the service context\n",
    "\n",
    "service_context = ServiceContext.from_defaults()\n",
    "\n",
    "#setup the storage context\n",
    "\n",
    "graph_store = SimpleGraphStore()\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "#Construct the Knowlege Graph Index\n",
    "index = KnowledgeGraphIndex.from_documents( documents=documents,\n",
    "                                           max_triplets_per_chunk=3,\n",
    "                                           service_context=service_context,\n",
    "                                           storage_context=storage_context,\n",
    "                                          include_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.indices.knowledge_graph.base.KnowledgeGraphIndex at 0x7f919b2bb0a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have any information about masked attention based on the given context.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is masked attention?\"\n",
    "query_engine = index.as_query_engine(include_text=True,\n",
    "                                     response_mode =\"tree_summarize\",\n",
    "                                     embedding_mode=\"hybrid\",\n",
    "                                     similarity_top_k=5,)\n",
    "#\n",
    "message_template =f\"\"\"<|system|>Please check if the following pieces of context has any mention of the keywords provided in the Question. If not then don't know the answer, just say that you don't know. Stop there. Please donot try to make up an answer.</s>\n",
    "<|user|>\n",
    "Question: {query}\n",
    "Helpful Answer:\n",
    "</s>\"\"\"\n",
    "#\n",
    "response = query_engine.query(message_template)\n",
    "#\n",
    "print(response.response.split(\"<|assistant|>\")[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know the answer to your question.\n"
     ]
    }
   ],
   "source": [
    "query =\"What is different about transformers, compared to RNN and LSTM\"\n",
    "message_template =f\"\"\"<|system|>Please check if the following pieces of context has any mention of the  keywords provided in the Question.If not then don't know the answer, just say that you don't know.Stop there.Please donot try to make up an answer.</s>\n",
    "<|user|>\n",
    "Question: {query}\n",
    "Helpful Answer:\n",
    "</s>\"\"\"\n",
    "#\n",
    "response = query_engine.query(message_template)\n",
    "#\n",
    "print(response.response.split(\"<|assistant|>\")[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "from IPython.display import display\n",
    "g = index.get_networkx_graph()\n",
    "net = Network(notebook=True,cdn_resources=\"in_line\",directed=True)\n",
    "net.from_nx(g)\n",
    "net.show(\"/Users/tolgadincer/Documents/AI_Projects/RAG_KnowledgeGraph_Llama-Index/graph.html\")\n",
    "net.save_graph(\"/Users/tolgadincer/Documents/AI_Projects/RAG_KnowledgeGraph_Llama-Index/Knowledge_graph.html\")\n",
    "#\n",
    "import IPython\n",
    "IPython.display.HTML(filename=\"/Users/tolgadincer/Documents/AI_Projects/RAG_KnowledgeGraph_Llama-Index/Knowledge_graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context.persist()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
