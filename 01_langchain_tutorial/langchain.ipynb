{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"], temperature = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Turkey is Ankara.\n"
     ]
    }
   ],
   "source": [
    "text=\"What is the capital of Turkey?\"\n",
    "print(llm.invoke(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_hugggingface = HuggingFaceHub(repo_id = \"google/flan-t5-large\", model_kwargs ={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "output = llm_hugggingface.predict(\"What is the capital of Russia?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the way ai looks at me i love the way ai looks at me i love the way ai looks at me i love the way ai looks at me i love the way ai looks at me i love the way ai\n"
     ]
    }
   ],
   "source": [
    "output = llm_hugggingface.predict(\"please write a short poem about AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates and LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of Turkey'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'], \n",
    "                                 template= \"Tell me the capital of {country}\")\n",
    "prompt_template.format(country = \"Turkey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of Turkey is Ankara.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm = llm, prompt = prompt_template)\n",
    "chain.run(\"Turkey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Chains Using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "                               template = \"Tell me the capital of {country}\")\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "                                 template = \"Give me some nice places to visit in {capital}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain = LLMChain(llm = llm, prompt= famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Here are some nice places to visit in Ankara:\\n\\n1. Anıtkabir: This is the mausoleum of Mustafa Kemal Atatürk, the founder of modern Turkey. It is a grand structure with beautiful gardens and is a must-visit for anyone interested in Turkish history.\\n\\n2. Kızılay Square: This is the heart of Ankara and a popular meeting place for locals. It is surrounded by shops, restaurants, and cafes, making it a great spot for people-watching and experiencing the city's vibrant atmosphere.\\n\\n3. Ankara Castle: Located on a hilltop, this medieval castle offers stunning views of the city. It is also home to several museums, including the Museum of Anatolian Civilizations, which displays artifacts from the region's ancient civilizations.\\n\\n4. Atakule Tower: This 410-foot tall tower offers panoramic views of Ankara and its surrounding mountains. It also has a revolving restaurant at the top, making it a popular spot for a romantic dinner.\\n\\n5. Gençlik Park: This park is a popular recreational spot for locals and tourists alike. It has a lake, walking paths, amusement park rides, and a small zoo, making it a great place to spend a day with family or friends.\\n\\n6.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains = [capital_chain,famous_chain])\n",
    "chain.run(\"Turkey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "                               template = \"Tell me the capital of {country}\")\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_template, output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "                                 template = \"Give me some nice places to visit in {capital}\")\n",
    "famous_chain = LLMChain(llm = llm, prompt= famous_template,output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains = [capital_chain,famous_chain],\n",
    "                        input_variables=['country'],\n",
    "                        output_variables=['capital','places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tolgadincer/Documents/AI_Projects/langchain/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'Turkey',\n",
       " 'capital': '\\n\\nAnkara',\n",
       " 'places': \", Turkey:\\n\\n1. Anıtkabir (Atatürk's Mausoleum)\\n2. Ulus Square\\n3. Ankara Citadel\\n4. Kızılay Square\\n5. Anadolu Medeniyetleri Müzesi (Museum of Anatolian Civilizations)\\n6. Atakule Tower\\n7. Eymir Lake\\n8. Kocatepe Mosque\\n9. Hamamönü Neighborhood\\n10. Gençlik Parkı (Youth Park)\\n11. Aslanhane Mosque\\n12. Hacı Bayram Mosque and Complex\\n13. Ankara Ethnography Museum\\n14. Museum of Anatolian Civilizations\\n15. Ankara Castle\\n16. Anka Mall\\n17. Ankara Zoo\\n18. Karum Shopping Center\\n19. Roman Baths of Ankara\\n20. Armada Shopping and Entertainment Center.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':\"Turkey\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatmodels with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tolgadincer/Documents/AI_Projects/langchain/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"], temperature = 0.6,model = 'gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As of my last update, Joker and Bane are both currently incarcerated in Arkham Asylum. Joker is being held in a maximum-security cell due to his unpredictable and dangerous nature. Bane, on the other hand, is being closely monitored due to his physical strength and intelligence. Both villains are considered to be high-risk individuals and require constant supervision.')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"I am Batman and you are an AI assistant for me\"),\n",
    "    HumanMessage(content = \"Give me the current statuses of Joker and Bane\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. When the user gives any input, you should generate 5 words synonyms in a comma separated list\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' brilliant', ' sharp', ' astute']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
